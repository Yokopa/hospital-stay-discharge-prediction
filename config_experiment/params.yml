# -----------------------
# Logistic regression parameter sets
# -----------------------
logistic_regression:
  default:
    classifier:
      class: "LogisticRegression"
      params:
        solver: "saga" #  efficient for problems with large datasets and high-dimensional data
        max_iter: 2000
        penalty: "l2"
        C: 1.0
        class_weight: "balanced"
        n_jobs: -1

  # Add a new parameter set for L1 regularization
  l1_balanced:
    classifier:
      class: "LogisticRegression"
      params:
        # Key changes for L1 regularization:
        penalty: "l1"
        solver: "liblinear" # 'liblinear' is a good choice for L1, especially for smaller datasets.
                            # 'saga' also supports L1, but 'liblinear' is often simpler/faster for this.
        C: 0.1 # Start with a lower C (stronger regularization) than the L2 default of 1.0
        
        # Keep these as they were:
        class_weight: "balanced"
        max_iter: 1000 # Can adjust if needed, but 1000 is usually sufficient
        random_state: 42 # Ensure reproducibility
        # n_jobs: -1 # 'liblinear' solver generally doesn't use n_jobs for parallelization,
                     # so you can remove or keep it; it might be ignored.

# -----------------------
# Linear regression parameter sets
# -----------------------
linear_regression:
  default:
    regressor:
      class: "LinearRegression"
      params: {}

# -----------------------
# LightGBM parameter sets
# -----------------------
lightgbm:
  default:
    classifier:
      class: "LGBMClassifier"
      params: {}
    regressor:
      class: "LGBMRegressor"
      params: {}

  default_balanced:
    classifier:
      class: "LGBMClassifier"
      use_sample_weight: true  # <-- internal flag, not passed to model
      params: {}
    regressor:
      class: "LGBMRegressor"
      params: {}

  trial_fast:
    classifier:
      class: "LGBMClassifier"
      use_sample_weight: true  # <-- internal flag, not passed to model
      params:
        n_estimators: 100         # controls runtime, low for fast tests
        max_depth: 6              # shallow trees = fast and general
        learning_rate: 0.1        # higher than default = faster convergence
        n_jobs: -1
    regressor:
      class: "LGBMRegressor"
      params:
        n_estimators: 100
        max_depth: 6
        learning_rate: 0.1
        n_jobs: -1

# -----------------------
# CatBoost parameter sets
# -----------------------
catboost:
  default:
    classifier:
      class: "CatBoostClassifier"
      params: {}
    regressor:
      class: "CatBoostRegressor"
      params: {}

  default_balanced:
    classifier:
      class: "CatBoostClassifier"
      use_sample_weight: true  # <-- internal flag
      params:
        auto_class_weights: "Balanced"  # native CatBoost support
    regressor:
      class: "CatBoostRegressor"
      params: {}

  trial_fast:
    classifier:
      class: "CatBoostClassifier"
      use_sample_weight: true  # <-- internal flag
      params:
        auto_class_weights: "Balanced"  # native CatBoost support
        iterations: 100
        depth: 6
        learning_rate: 0.1
        verbose: 0
    regressor:
      class: "CatBoostRegressor"
      params:
        iterations: 100
        depth: 6
        learning_rate: 0.1
        verbose: 0

# -----------------------
# XGBoost parameter sets
# -----------------------
xgboost:
  default:
    classifier:
      class: "XGBClassifier"
      params:
        enable_categorical: true
        tree_method: "hist"

    regressor:
      class: "XGBRegressor"
      params:
        enable_categorical: true
        tree_method: "hist"

  default_balanced:
    classifier:
      class: "XGBClassifier"
      params:
        enable_categorical: true
        tree_method: "hist"
      use_sample_weight: true  # <-- internal flag

    regressor:
      class: "XGBRegressor"
      params:
        enable_categorical: true
        tree_method: "hist"

  trial_fast:
    classifier:
      class: "XGBClassifier"
      params:
        n_estimators: 100
        max_depth: 6
        learning_rate: 0.1
        enable_categorical: true
        tree_method: "hist"
        n_jobs: -1
      use_sample_weight: true  # <-- internal flag, not passed to model
    regressor:
      class: "XGBRegressor"
      params:
        n_estimators: 100
        max_depth: 6
        learning_rate: 0.1
        enable_categorical: true
        tree_method: "hist"
        n_jobs: -1

# -----------------------








  default_balanced:
    classifier:
      class: "CatBoostClassifier"
      params:
        auto_class_weights: Balanced

    regressor:
      class: "CatBoostRegressor"
      params: {}




xgboost:
  default:
    classifier:
      n_estimators: 1000
      learning_rate: 0.05
      max_depth: 6
      random_state: 42
    regressor:
      n_estimators: 1000
      learning_rate: 0.05
      max_depth: 6
      random_state: 42
  # Add more param sets similarly...



xgboost:
  classifier:
    class: xgboost.XGBClassifier
    params:
      n_estimators: 100
      max_depth: 4
      learning_rate: 0.1
      objective: binary:logistic
      use_label_encoder: false
      eval_metric: logloss  # suppress warning
  regressor:
    class: xgboost.XGBRegressor
    params:
      n_estimators: 100
      max_depth: 4
      learning_rate: 0.1
      objective: reg:squarederror



# lightgbm

  # fast_tree:
  #   classifier:
  #     n_estimators: 100
  #     learning_rate: 0.1
  #     max_depth: 6
  #     num_leaves: 15

  #   regressor:
  #     n_estimators: 100
  #     learning_rate: 0.1
  #     max_depth: 6
  #     num_leaves: 15


  # default:
  #   classifier:
  #     n_estimators: 1000
  #     learning_rate: 0.05
  #     max_depth: -1
  #     num_leaves: 31
  #     random_state: config.random_seed

  #   regressor:
  #     n_estimators: 1000
  #     learning_rate: 0.05
  #     max_depth: -1
  #     num_leaves: 31
  #     random_state: config.random_seed

  # deep_trees:
  #   classifier:
  #     n_estimators: 500
  #     learning_rate: 0.01
  #     max_depth: 20
  #     num_leaves: 100
  #     random_state: 42
  #   regressor:
  #     n_estimators: 500
  #     learning_rate: 0.01
  #     max_depth: 20
  #     num_leaves: 100
  #     random_state: 42



# catboost
    # classifier:
    #   iterations: 500
    #   learning_rate: 0.05
    #   depth: 6
    #   random_seed: 42
    # regressor:
    #   iterations: 500
    #   learning_rate: 0.05
    #   depth: 6
    #   random_seed: 42